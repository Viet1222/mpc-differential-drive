import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Twist, PoseStamped
from nav_msgs.msg import Odometry, Path
import numpy as np
import math

# DÃ¹ng Solver CÆ¡ báº£n (Tracking)
from mpc_bot.mpc_solver import MPCSolver

def euler_from_quaternion(x, y, z, w):
    t3 = +2.0 * (w * z + x * y)
    t4 = +1.0 - 2.0 * (y * y + z * z)
    return math.atan2(t3, t4)

class ScenarioNav(Node):
    def __init__(self):
        super().__init__('scenario_nav')
        
        self.dt = 0.1
        self.N = 20
        self.solver = MPCSolver(self.N, self.dt)
        self.get_logger().info("ğŸ“ Ká»‹ch báº£n ÄI Äáº¾N ÄIá»‚M ÄÃCH (Point-to-Point) Ä‘Ã£ sáºµn sÃ ng!")
        self.get_logger().info("ğŸ‘‰ HÃ£y dÃ¹ng cÃ´ng cá»¥ '2D Goal Pose' trÃªn Rviz Ä‘á»ƒ chá»n Ä‘iá»ƒm Ä‘áº¿n!")

        # Setup ROS
        self.sub_odom = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)
        
        # Láº¯ng nghe lá»‡nh tá»« Rviz (NÃºt 2D Goal Pose)
        self.sub_goal = self.create_subscription(PoseStamped, '/goal_pose', self.goal_callback, 10)
        
        self.pub_cmd = self.create_publisher(Twist, '/cmd_vel', 10)
        self.pub_ref_path = self.create_publisher(Path, '/mpc/reference_path', 10)
        self.pub_pred_path = self.create_publisher(Path, '/mpc/predicted_path', 10)
        
        self.timer = self.create_timer(self.dt, self.control_loop)

        # Tráº¡ng thÃ¡i
        self.current_state = np.array([0.0, 0.0, 0.0]) 
        self.got_odom = False
        
        # Biáº¿n quáº£n lÃ½ má»¥c tiÃªu
        self.has_goal = False
        self.goal_state = np.array([0.0, 0.0, 0.0]) # [x, y, theta]
        self.is_reached = False

    def odom_callback(self, msg):
        x = msg.pose.pose.position.x
        y = msg.pose.pose.position.y
        q = msg.pose.pose.orientation
        theta = euler_from_quaternion(q.x, q.y, q.z, q.w)
        self.current_state = np.array([x, y, theta])
        self.got_odom = True

    def goal_callback(self, msg):
        """HÃ m nÃ y cháº¡y khi báº¡n click chuá»™t trÃªn Rviz"""
        gx = msg.pose.position.x
        gy = msg.pose.position.y
        
        # Láº¥y gÃ³c theta má»¥c tiÃªu tá»« quaternion cá»§a chuá»™t
        q = msg.pose.orientation
        gtheta = euler_from_quaternion(q.x, q.y, q.z, q.w)
        
        self.goal_state = np.array([gx, gy, gtheta])
        self.has_goal = True
        self.is_reached = False
        self.get_logger().info(f"ğŸ¯ Nháº­n má»¥c tiÃªu má»›i: X={gx:.2f}, Y={gy:.2f}")

    def generate_path_to_goal(self):
        """
        Táº¡o quá»¹ Ä‘áº¡o ná»™i suy tá»« vá»‹ trÃ­ hiá»‡n táº¡i Ä‘áº¿n Ä‘Ã­ch.
        ÄÆ¡n giáº£n nháº¥t: Táº¡o Ä‘Æ°á»ng tháº³ng ná»‘i 2 Ä‘iá»ƒm.
        """
        ref_matrix = np.zeros((3, self.N))
        
        # Vector tá»« xe Ä‘áº¿n Ä‘Ã­ch
        dx = self.goal_state[0] - self.current_state[0]
        dy = self.goal_state[1] - self.current_state[1]
        dist_to_goal = math.sqrt(dx**2 + dy**2)
        
        # Náº¿u Ä‘Ã£ Ä‘áº¿n ráº¥t gáº§n Ä‘Ã­ch (< 10cm) -> Dá»«ng láº¡i
        if dist_to_goal < 0.1:
            self.is_reached = True
            # Táº¡o quá»¹ Ä‘áº¡o Ä‘á»©ng yÃªn táº¡i Ä‘Ã­ch
            for i in range(self.N):
                ref_matrix[:, i] = self.goal_state
            return ref_matrix

        # Náº¿u chÆ°a Ä‘áº¿n Ä‘Ã­ch -> Táº¡o Ä‘Æ°á»ng dáº«n
        # Logic: Giáº£ sá»­ ta muá»‘n Ä‘i Ä‘áº¿n Ä‘Ã­ch vá»›i váº­n tá»‘c v_desired
        v_des = 0.5
        
        # GÃ³c hÆ°á»›ng vá» Ä‘Ã­ch
        angle_to_goal = math.atan2(dy, dx)
        
        for i in range(self.N):
            # TÃ­nh quÃ£ng Ä‘Æ°á»ng dá»± kiáº¿n Ä‘i Ä‘Æ°á»£c sau i bÆ°á»›c
            dist_future = v_des * (i * self.dt)
            
            # Náº¿u quÃ£ng Ä‘Æ°á»ng nÃ y vÆ°á»£t quÃ¡ Ä‘Ã­ch -> Káº¹p láº¡i táº¡i Ä‘Ã­ch
            if dist_future > dist_to_goal:
                ref_matrix[0, i] = self.goal_state[0]
                ref_matrix[1, i] = self.goal_state[1]
                ref_matrix[2, i] = self.goal_state[2] # HÆ°á»›ng cuá»‘i cÃ¹ng mong muá»‘n
            else:
                # Ná»™i suy tuyáº¿n tÃ­nh (Linear Interpolation)
                ratio = dist_future / dist_to_goal
                ref_matrix[0, i] = self.current_state[0] + dx * ratio
                ref_matrix[1, i] = self.current_state[1] + dy * ratio
                
                # HÆ°á»›ng Ä‘i: HÆ°á»›ng vá» Ä‘Ã­ch
                # Tuy nhiÃªn, khi gáº§n Ä‘áº¿n nÆ¡i, cáº§n xoay xe vá» Ä‘Ãºng hÆ°á»›ng goal
                # Äá»ƒ Ä‘Æ¡n giáº£n: Äoáº¡n Ä‘áº§u hÆ°á»›ng vá» Ä‘Ã­ch, Ä‘oáº¡n cuá»‘i xoay vá» goal_theta
                if dist_to_goal > 0.5:
                    ref_matrix[2, i] = angle_to_goal
                else:
                    # Gáº§n Ä‘Ã­ch thÃ¬ ná»™i suy gÃ³c xoay
                    ref_matrix[2, i] = self.goal_state[2]
                    
        return ref_matrix

    def visualize_path(self, trajectory_matrix, publisher):
        path_msg = Path()
        path_msg.header.frame_id = 'odom'
        path_msg.header.stamp = self.get_clock().now().to_msg()
        for i in range(trajectory_matrix.shape[1]):
            pose = PoseStamped()
            pose.header = path_msg.header
            pose.pose.position.x = float(trajectory_matrix[0, i])
            pose.pose.position.y = float(trajectory_matrix[1, i])
            pose.pose.position.z = 0.0
            pose.pose.orientation.w = 1.0 
            path_msg.poses.append(pose)
        publisher.publish(path_msg)

    def control_loop(self):
        if not self.got_odom:
            return

        if not self.has_goal:
            # Náº¿u chÆ°a cÃ³ goal, Ä‘á»©ng yÃªn hoáº·c giá»¯ vá»‹ trÃ­ cÅ©
            # Gá»­i lá»‡nh v=0
            self.pub_cmd.publish(Twist())
            return

        # 1. Táº¡o Ä‘Æ°á»ng dáº«n Ä‘á»™ng (Dynamic Path Generation)
        ref_traj = self.generate_path_to_goal()
        
        # 2. Xá»­ lÃ½ gÃ³c xoay (Unwrap)
        full_theta = np.concatenate(([self.current_state[2]], ref_traj[2, :]))
        full_theta_unwrapped = np.unwrap(full_theta)
        ref_traj[2, :] = full_theta_unwrapped[1:]
        
        # 3. Giáº£i MPC
        u_opt, x_pred = self.solver.solve(self.current_state, ref_traj)
        
        # 4. Gá»­i lá»‡nh (Náº¿u Ä‘Ã£ Ä‘áº¿n Ä‘Ã­ch thÃ¬ force stop)
        cmd = Twist()
        if self.is_reached:
            cmd.linear.x = 0.0
            cmd.angular.z = 0.0
            self.get_logger().info("ğŸ ÄÃ£ Ä‘áº¿n Ä‘Ã­ch!", once=True)
        else:
            cmd.linear.x = float(u_opt[0])
            cmd.angular.z = float(u_opt[1])
            
        self.pub_cmd.publish(cmd)
        
        # 5. Hiá»ƒn thá»‹
        self.visualize_path(ref_traj, self.pub_ref_path)
        self.visualize_path(x_pred, self.pub_pred_path)

def main(args=None):
    rclpy.init(args=args)
    node = ScenarioNav()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
    
